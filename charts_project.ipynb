{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "import requests\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import logging\n",
    "#os.makedirs('./check', exist_ok=True)\n",
    "# logging.basicConfig(\n",
    "#     filename='./check/data_processing.log',\n",
    "#     level=logging.INFO,\n",
    "#     format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "# )\n",
    "#logging.basicConfig(filename='./check/debug.log', level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def fetch_visits(api_url, start_date, end_date):\n",
    "    try:\n",
    "        response = requests.get(f\"{api_url}/visits?\", params={'begin': start_date, 'end': end_date})\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Печать JSON-ответа\n",
    "        visits_data = response.json()  # Получаем данные из ответа\n",
    "        file_path = './check/http_visits.json'\n",
    "        # with open(file_path, 'w') as f:\n",
    "        #     json.dump(visits_data, f, indent=4, default=str)  # Используем indent для удобочитаемости\n",
    "\n",
    "        # print(f\"Data saved to {file_path}\")\n",
    "        return visits_data         # Возвращаем данные\n",
    "        \n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f\"HTTP error occurred: {err}\")\n",
    "        return None\n",
    "    except Exception as err:\n",
    "        print(f\"Other error occurred: {err}\")\n",
    "        return None\n",
    "\n",
    "def fetch_registrations(api_url, start_date, end_date):\n",
    "    try:\n",
    "        response = requests.get(f\"{api_url}/registrations?\", params={'begin': start_date, 'end': end_date})\n",
    "        response.raise_for_status()\n",
    "        registration_data = response.json()  # Получаем данные из ответа\n",
    "        file_path = './check/http_registrations.json'\n",
    "        # with open(file_path, 'w') as f:\n",
    "        #     json.dump(registration_data, f, indent=4, default=str)  # Используем indent для удобочитаемости\n",
    "\n",
    "        # print(f\"Data saved to {file_path}\")        # Печатаем полученные данные\n",
    "        \n",
    "        return registration_data\n",
    "    except requests.exceptions.HTTPError as err:\n",
    "        print(f\"HTTP error occurred: {err}\")\n",
    "        return None\n",
    "    except Exception as err:\n",
    "        print(f\"Other error occurred: {err}\")\n",
    "        return None\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_url = os.getenv(\"API_URL\")\n",
    "start_date = os.getenv(\"DATE_BEGIN\")\n",
    "end_date = os.getenv(\"DATE_END\")\n",
    "\n",
    "visits_data = fetch_visits(api_url, start_date, end_date)\n",
    "registrations_data = fetch_registrations(api_url, start_date, end_date)\n",
    "\n",
    "if visits_data is None or registrations_data is None:\n",
    "    print(\"Failed to fetch data. Exiting.\")\n",
    "    exit(1)\n",
    "# Convert data to DataFrames and prepare it\n",
    "# Преобразуем данные в DataFrames\n",
    "df_reg = pd.DataFrame(registrations_data)\n",
    "df_vis = pd.DataFrame(visits_data)\n",
    "\n",
    "# Фильтруем визиты, исключая ботов\n",
    "df_vis = df_vis[~df_vis['user_agent'].str.contains(\"bot\", case=False, na=False)]\n",
    "#logging.info(f\"Filtered Visits (no bots):\\n{df_vis.head()}\")\n",
    "\n",
    "# Преобразование столбца datetime\n",
    "df_reg['datetime'] = pd.to_datetime(df_reg['datetime'])\n",
    "df_vis['datetime'] = pd.to_datetime(df_vis['datetime'])\n",
    "#logging.info(\"Datetime conversion done.\")\n",
    "\n",
    "# Оставляем только последний визит для каждого visit_id\n",
    "df_vis_last = df_vis.sort_values('datetime').groupby('visit_id').last().reset_index()\n",
    "\n",
    "# Заполняем отсутствующие значения\n",
    "df_vis_last = df_vis_last.fillna(0)\n",
    "df_reg = df_reg.fillna(0)\n",
    "\n",
    "# Группируем последние визиты по дате и платформе\n",
    "df_vis_grouped = df_vis_last.groupby([df_vis_last['datetime'].dt.date, 'platform']).size().reset_index(name='visits')\n",
    "#logging.info(f\"Grouped Last Visits DataFrame:\\n{df_vis_grouped}\")\n",
    "\n",
    "# Группируем регистрации по дате и платформе\n",
    "df_reg_grouped = df_reg.groupby([df_reg['datetime'].dt.date, 'platform']).size().reset_index(name='registrations')\n",
    "#logging.info(f\"Grouped Registrations DataFrame:\\n{df_reg_grouped}\")\n",
    "\n",
    "# Объединяем DataFrames\n",
    "merged_df = pd.merge(df_vis_grouped, df_reg_grouped, on=['datetime', 'platform'], how='left')\n",
    "#logging.info(f\"Merged DataFrame (before filling NaN in registrations):\\n{merged_df}\")\n",
    "\n",
    "# Заполняем отсутствующие значения в регистрациях\n",
    "merged_df['registrations'] = merged_df['registrations'].fillna(0)\n",
    "\n",
    "# Вычисляем конверсию\n",
    "merged_df['conversion'] = merged_df.apply(\n",
    "    lambda row: (row['registrations'] / row['visits'] * 100) if row['visits'] > 0 else 0,\n",
    "    axis=1\n",
    ")\n",
    "#logging.info(f\"Merged DataFrame (after conversion calculation):\\n{merged_df}\")\n",
    "\n",
    "# Преобразуем дату в миллисекунды для JSON\n",
    "merged_df['date_group'] = pd.to_datetime(merged_df['datetime']).astype(int) // 10**6\n",
    "#logging.info(f\"Final DataFrame with milliseconds:\\n{merged_df[['datetime', 'date_group']]}\")\n",
    "merged_df['conversion'] = merged_df['conversion'].apply(lambda x: round(x, 10))\n",
    "# Создаем финальный JSON\n",
    "final_json = {\n",
    "    \"date_group\": {str(i): int(v) for i, v in enumerate(merged_df['date_group'])},\n",
    "    \"platform\": {str(i): p for i, p in enumerate(merged_df['platform'])},\n",
    "    \"visits\": {str(i): int(v) for i, v in enumerate(merged_df['visits'])},\n",
    "    \"registrations\": {str(i): int(v) for i, v in enumerate(merged_df['registrations'])},\n",
    "    \"conversion\": {str(i): v for i, v in enumerate(merged_df['conversion'])}\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open('conversion.json', 'w') as f:\n",
    "    json.dump(final_json, f, indent=4)\n",
    "#logging.info(\"Saved final JSON to './check/conversion.json'\")\n",
    "\n",
    "ads_df = pd.read_csv('ads.csv')\n",
    "#ads_df['date'] = pd.to_datetime(ads_df['date'], errors='coerce')  # Преобразуем в datetime, обрабатываем некорректные значения\n",
    "#ads_df['date'] = ads_df['date'].fillna(pd.Timestamp(0))  # Заменяем NaT на дефолтное значение\n",
    "#ads_df['date'] = ads_df['date'].astype(int) // 10**6  # Преобразуем в Unix timestamp в миллисекундах\n",
    "ads_df['date'] = pd.to_datetime(ads_df['date']).dt.strftime('%Y-%m-%d')\n",
    "ads_df['date'] = pd.to_datetime(ads_df['date']).astype(int) // 10 ** 6\n",
    "#logging.info(f\"Dates from ads_df (formatted to YYYY-MM-DD):\\n{ads_df['date'].tolist()}\")\n",
    "ads_dates_json = {\n",
    "    \"date_group\": {str(i): int(v) for i, v in enumerate(ads_df['date'])}  # Даты рекламы после преобразования\n",
    "}\n",
    "\n",
    "# Сохраняем JSON с датами из ads_df\n",
    "# with open('./check/ads_dates.json', 'w') as f:\n",
    "#     json.dump(ads_dates_json, f, indent=4)\n",
    "# Группируем данные рекламы по дате\n",
    "ads_cost = ads_df.groupby('date').agg({'cost': 'sum'}).reset_index().fillna(0)\n",
    "ads_campaign = ads_df.groupby('date').agg({'utm_campaign': 'first'}).reset_index().fillna('none')\n",
    "\n",
    "# Выполняем левое объединение данных рекламы с основными данными по дате\n",
    "# Это позволит сопоставить данные рекламы только для дат, которые есть в merged_df\n",
    "ads_merged = pd.merge(merged_df[['date_group']], ads_cost, how='left', left_on='date_group', right_on='date')\n",
    "\n",
    "# Теперь сопоставляем utm_campaign по дате\n",
    "ads_merged = pd.merge(ads_merged, ads_campaign[['date', 'utm_campaign']], how='left', left_on='date_group', right_on='date')\n",
    "\n",
    "# Заменяем NaN на 0 для столбца cost и 'none' для utm_campaign, если данных нет для какой-то даты\n",
    "ads_merged['cost'] = ads_merged['cost'].fillna(0)\n",
    "ads_merged['utm_campaign'] = ads_merged['utm_campaign'].fillna('none')\n",
    "\n",
    "# Создаем финальный JSON для рекламы (второй JSON)\n",
    "final_ads_json = {\n",
    "    \"date_group\": {str(i): int(v) for i, v in enumerate(merged_df['date_group'])},  # Используем даты из merged_df\n",
    "    \"visits\": {str(i): int(v) for i, v in enumerate(merged_df['visits'])},\n",
    "    \"registrations\": {str(i): int(v) for i, v in enumerate(merged_df['registrations'])},\n",
    "    \"cost\": {str(i): int(ads_merged.iloc[i]['cost']) for i in range(len(merged_df))},  # Заполняем затраты из рекламы\n",
    "    \"utm_campaign\": {str(i): ads_merged.iloc[i]['utm_campaign'] for i in range(len(merged_df))}  # Заполняем utm_campaign из рекламы\n",
    "}\n",
    "\n",
    "# Сохраняем финальный JSON для рекламы\n",
    "with open('ads.json', 'w') as f:\n",
    "    json.dump(final_ads_json, f, indent=4)\n",
    "\n",
    "\n",
    "\n",
    "# Подготовка данных с новыми именами\n",
    "summary_df = pd.DataFrame(final_json)  # Переименована переменная merged_df\n",
    "ads_summary_df = pd.DataFrame(final_ads_json)  # Переименована переменная ads_merged\n",
    "\n",
    "\n",
    "# Преобразование даты из UNIX времени в человекочитаемый формат\n",
    "summary_df['date_group'] = pd.to_datetime(summary_df['date_group'], unit='ms')\n",
    "\n",
    "# Удаляем строки с рекламными кампаниями, где 'utm_campaign' равен None\n",
    "ads_summary_df = ads_summary_df[ads_summary_df['utm_campaign'].notna()]\n",
    "summary_df.head()\n",
    "# Создание директории для графиков, если она не существует\n",
    "if not os.path.exists('charts'):\n",
    "    os.makedirs('charts')\n",
    "\n",
    "# Функция для сохранения графиков\n",
    "def save_plot(plt, filename):\n",
    "    # Генерируем полный путь для сохранения файла\n",
    "    path = os.path.join('charts', filename)\n",
    "    \n",
    "    # Выводим путь для проверки\n",
    "    print(f\"Saving plot to: {path}\")\n",
    "    \n",
    "    # Сохраняем график\n",
    "    plt.savefig(path, bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    # Закрываем график\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Функция для аннотации всех локальных вершин и низин\n",
    "def annotate_peaks_troughs(ax, x_data, y_data):\n",
    "    # Проход по точкам и нахождение локальных максимумов и минимумов\n",
    "    for i in range(1, len(y_data) - 1):\n",
    "        # Локальный максимум\n",
    "        if y_data[i] > y_data[i - 1] and y_data[i] > y_data[i + 1]:\n",
    "            ax.annotate(f'{y_data[i]:.2f}%', xy=(x_data[i], y_data[i]),\n",
    "                        xytext=(0, 5), textcoords='offset points', color='green', fontsize=10, ha='center')\n",
    "        # Локальный минимум\n",
    "        if y_data[i] < y_data[i - 1] and y_data[i] < y_data[i + 1]:\n",
    "            ax.annotate(f'{y_data[i]:.2f}%', xy=(x_data[i], y_data[i]),\n",
    "                        xytext=(0, -10), textcoords='offset points', color='red', fontsize=10, ha='center')\n",
    "\n",
    "\n",
    "# 1 Итоговые визиты\n",
    "merged_df['date_group'] = pd.to_datetime(merged_df['date_group'], unit='ms')\n",
    "aggregated_df = merged_df.groupby('date_group', as_index=False)['visits'].sum()\n",
    "# Агрегация данных: группируем по дате и суммируем визиты\n",
    "aggregated_df['x_pos'] = range(len(aggregated_df))  # Начинаем с 0, а не с 1\n",
    "\n",
    "plt.figure(figsize=(48, 24))\n",
    "\n",
    "# Построение столбикового графика с явным выравниванием по центру\n",
    "bars = plt.bar(aggregated_df['x_pos'], aggregated_df['visits'], color='skyblue', align='center')\n",
    "\n",
    "# Добавление значений над каждым столбцом\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval, int(yval), ha='center', va='bottom')  # Значение над столбцом\n",
    "\n",
    "# Добавление заголовка и подписей осей\n",
    "plt.title('Итоговые визиты')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Количество визитов')\n",
    "\n",
    "# Замена числовых индексов на реальные даты (настраиваем метки на основе позиций столбиков)\n",
    "plt.xticks(aggregated_df['x_pos'], aggregated_df['date_group'].dt.strftime('%Y-%m-%d'), rotation=45, ha='right')\n",
    "\n",
    "# Сетка по оси Y\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Установка пределов по оси Y\n",
    "plt.ylim(0, aggregated_df['visits'].max() * 1.1)  # Установите максимум на 10% больше максимума\n",
    "\n",
    "# Сохранение графика\n",
    "save_plot(plt, 'Итоговые визиты.png')\n",
    "\n",
    "# Отображение графика\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2 график Итоговые визиты с разбивкой по платформам: web, android, ios\n",
    "# Преобразуем данные в формат для построения столбчатой диаграммы\n",
    "\n",
    "pivot_data = summary_df.pivot_table(index='date_group', columns='platform', values='visits', aggfunc='sum')\n",
    "\n",
    "# Построение столбчатой диаграммы с накоплением\n",
    "pivot_data.plot(kind='bar', stacked=True, figsize=(48, 24), color=plt.cm.Paired.colors)\n",
    "\n",
    "# Настройки графика\n",
    "plt.title('Итоговые визиты по платформам (с накоплением)')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Количество визитов')\n",
    "plt.xticks(aggregated_df['x_pos'], aggregated_df['date_group'].dt.strftime('%Y-%m-%d'), rotation=45, ha='right')\n",
    "plt.xticks(rotation=45)  # Поворачиваем метки оси X для лучшей читаемости\n",
    "plt.grid(axis='y')  # Сетка только по оси Y\n",
    "plt.grid(axis='x')\n",
    "plt.legend(title='Платформы')\n",
    "\n",
    "# Сохранение графика\n",
    "save_plot(plt, 'Итоговые визиты с разбивкой по платформам.png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. Итоговые регистрации\n",
    "\n",
    "# Создание фигуры\n",
    "plt.figure(figsize=(48, 24))\n",
    "\n",
    "# Преобразование столбца 'date_group' в формат datetime\n",
    "merged_df['date_group'] = pd.to_datetime(merged_df['date_group'], unit='ms')\n",
    "\n",
    "# Агрегация данных: группируем по дате и суммируем регистрации\n",
    "aggregated_df = merged_df.groupby('date_group', as_index=False)['registrations'].sum()\n",
    "\n",
    "# Построение столбикового графика\n",
    "bars = plt.bar(aggregated_df['date_group'], aggregated_df['registrations'], color='skyblue', align='center')\n",
    "\n",
    "# Добавление значений над каждым столбцом\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval, int(yval), ha='center', va='bottom')  # Значение над столбцом\n",
    "\n",
    "# Настройки графика\n",
    "plt.title('Итоговые регистрации')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Количество регистраций')\n",
    "\n",
    "# Установка меток оси X на все даты\n",
    "plt.xticks(aggregated_df['date_group'], aggregated_df['date_group'].dt.strftime('%Y-%m-%d'), rotation=45, ha='right')\n",
    "\n",
    "# Сетка по оси Y\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Установка пределов по оси Y\n",
    "plt.ylim(0, aggregated_df['registrations'].max() * 1.1)  # Установите максимум на 10% больше максимума\n",
    "\n",
    "# Сохранение графика\n",
    "save_plot(plt, 'Итоговые регистрации.png')\n",
    "\n",
    "# Отображение графика\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# # 4. Итоговые регистрации с разбивкой по платформам (линейный график)\n",
    "# Преобразуем данные в формат для построения столбчатой диаграммы\n",
    "pivot_data_registrations = summary_df.pivot_table(index='date_group', columns='platform', values='registrations', aggfunc='sum')\n",
    "\n",
    "# Построение столбчатой диаграммы с накоплением для регистраций\n",
    "pivot_data_registrations.plot(kind='bar', stacked=True, figsize=(48, 24), color=plt.cm.Paired.colors)\n",
    "\n",
    "# Настройки графика\n",
    "plt.title('Итоговые регистрации по платформам (с накоплением)')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Количество регистраций')\n",
    "\n",
    "# Установка меток оси X на все даты\n",
    "plt.xticks(ticks=range(len(pivot_data_registrations.index)), labels=pivot_data_registrations.index.strftime('%Y-%m-%d'), rotation=45, ha='right')\n",
    "\n",
    "# Сетка по оси Y\n",
    "plt.grid(axis='y')  # Сетка только по оси Y\n",
    "plt.grid(axis='x')  # Сетка по оси X\n",
    "\n",
    "plt.legend(title='Платформы')\n",
    "# Сохранение графика\n",
    "save_plot(plt, 'Итоговые регистрации с разбивкой по платформе.png')\n",
    "\n",
    "# Отображение графика\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # 5. Конверсия по каждой платформе\n",
    "\n",
    "# Создание фигуры с тремя подграфиками (по количеству платформ)\n",
    "fig, axs = plt.subplots(3, 1, figsize=(48, 24), sharex=True)\n",
    "\n",
    "# Платформы для построения\n",
    "platforms = ['web', 'android', 'ios']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i, platform in enumerate(platforms):\n",
    "    # Фильтрация данных по текущей платформе\n",
    "    platform_data = merged_df[merged_df['platform'] == platform]\n",
    "    \n",
    "    # Данные для построения графика\n",
    "    x_data = platform_data['datetime'].values\n",
    "    y_data = platform_data['conversion'].values\n",
    "    \n",
    "    # Построение линии для платформы\n",
    "    axs[i].plot(x_data, y_data, label=platform, color='b')\n",
    "    \n",
    "    # Добавление аннотаций на всех вершинах и низинах\n",
    "    annotate_peaks_troughs(axs[i], x_data, y_data)\n",
    "    \n",
    "    # Настройки для каждого графика\n",
    "    axs[i].set_title(f'Conversion Rate for {platform.capitalize()}')\n",
    "    axs[i].set_ylabel('Conversion Rate (%)')\n",
    "    axs[i].legend(loc='upper right')\n",
    "    axs[i].grid(True)\n",
    "\n",
    "# Общая настройка для оси X (дата)\n",
    "axs[2].set_xlabel('Date')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "\n",
    "save_plot(plt, 'Конверсия по каждой платформе.png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # 6. Средняя конверсия\n",
    "# Построение графика\n",
    "# Суммирование визитов и регистраций по всем платформам для каждой даты\n",
    "merged_df_grouped = merged_df.groupby('datetime').agg({\n",
    "    'visits': 'sum',\n",
    "    'registrations': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Пересчет конверсии\n",
    "merged_df_grouped['conversion'] = (merged_df_grouped['registrations'] / merged_df_grouped['visits'] * 100).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "# Построение единого графика\n",
    "plt.figure(figsize=(48, 24))\n",
    "\n",
    "# Данные для построения единого графика\n",
    "x_data = merged_df_grouped['datetime'].values\n",
    "y_data = merged_df_grouped['conversion'].values\n",
    "\n",
    "# Построение линии для суммарной конверсии\n",
    "plt.plot(x_data, y_data, label='Total Conversion', color='b')\n",
    "\n",
    "# Добавление аннотаций для всех вершин и низин\n",
    "annotate_peaks_troughs(plt.gca(), x_data, y_data)\n",
    "\n",
    "# Настройки графика\n",
    "plt.title('Overall Conversion Rate Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Conversion Rate (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Conversion')\n",
    "\n",
    "# Сохранение графика\n",
    "save_plot(plt, 'Средняя конверсия.png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 7. Стоимости реклам (упрощенный график без None)\n",
    "# Исключаем кампанию с названием 'none'\n",
    "# Настройка логирования\n",
    "\n",
    "# Исключаем кампанию с названием 'none'\n",
    "filtered_ads_df = ads_summary_df[ads_summary_df['utm_campaign'] != 'none']\n",
    "\n",
    "# Сортируем данные по дате\n",
    "filtered_ads_df = filtered_ads_df.sort_values(by='date_group')  # 'date_group' - название столбца с датами\n",
    "\n",
    "# Преобразуем 'date_group' в datetime для правильного отображения\n",
    "filtered_ads_df['date_group'] = pd.to_datetime(filtered_ads_df['date_group'], unit='ms')  # Если даты в миллисекундах\n",
    "\n",
    "# Получаем список уникальных кампаний\n",
    "campaigns = filtered_ads_df['utm_campaign'].unique()\n",
    "\n",
    "# Устанавливаем цвета для каждой кампании\n",
    "colors = cm.get_cmap('tab10', len(campaigns))  # Используем палитру с 10 цветами\n",
    "\n",
    "# Функция для нахождения локальных максимумов и минимумов\n",
    "def find_peaks_and_troughs(x_data, y_data):\n",
    "    peaks = []\n",
    "    troughs = []\n",
    "    \n",
    "    for i in range(1, len(y_data) - 1):\n",
    "        # Проверяем на максимум\n",
    "        if y_data[i] > y_data[i - 1] and y_data[i] > y_data[i + 1]:\n",
    "            peaks.append(i)  # Индекс локального максимума\n",
    "        # Проверяем на минимум\n",
    "        elif y_data[i] < y_data[i - 1] and y_data[i] < y_data[i + 1]:\n",
    "            troughs.append(i)  # Индекс локального минимума\n",
    "\n",
    "        # Дополнительная проверка для случаев, когда значения одинаковы\n",
    "        elif y_data[i] == y_data[i - 1] and y_data[i] > y_data[i + 1]:\n",
    "            peaks.append(i)  # Добавляем, если текущая равна предыдущей, но больше следующей\n",
    "        elif y_data[i] == y_data[i + 1] and y_data[i] < y_data[i - 1]:\n",
    "            troughs.append(i)  # Добавляем, если текущая равна следующей, но меньше предыдущей\n",
    "\n",
    "    # Логируем данные для отладки\n",
    "    logging.info(f\"Data: {y_data}, Peaks: {peaks}, Troughs: {troughs}\")\n",
    "    return peaks, troughs\n",
    "\n",
    "# Построение линейного графика\n",
    "plt.figure(figsize=(48, 24))  # Размер графика\n",
    "\n",
    "# Переменные для хранения данных\n",
    "prev_campaign = None\n",
    "x_data, y_data = [], []\n",
    "color_index = 0  # Для переключения цветов\n",
    "\n",
    "# Проход по каждой строке и построение линий с разными цветами\n",
    "for i, row in filtered_ads_df.iterrows():\n",
    "    campaign = row['utm_campaign']\n",
    "    \n",
    "    # Если текущая кампания отличается от предыдущей\n",
    "    if campaign != prev_campaign:\n",
    "        # Если есть данные для предыдущей кампании, рисуем линию\n",
    "        if prev_campaign is not None and len(x_data) > 0 and len(y_data) > 0:\n",
    "            plt.plot(x_data, y_data, label=prev_campaign, color=colors(color_index), linewidth=2)  # Установите желаемую толщину\n",
    "            \n",
    "            # Находим локальные максимумы и минимумы\n",
    "            peaks, troughs = find_peaks_and_troughs(x_data, y_data)\n",
    "            logging.info(f\"Campaign: {prev_campaign}, Peaks: {peaks}, Troughs: {troughs}\")  # Логирование информации\n",
    "            \n",
    "            # Аннотируем локальные максимумы и минимумы\n",
    "            last_peak_value = None  # Храним последнее аннотированное значение пика\n",
    "            last_trough_value = None  # Храним последнее аннотированное значение минимума\n",
    "            \n",
    "            # Объединяем индексы пиков и низин\n",
    "            for idx in sorted(peaks + troughs):  \n",
    "                # Проверяем, является ли текущий индекс максимумом или минимумом\n",
    "                if idx in peaks:\n",
    "                    if y_data[idx] != last_peak_value and (last_trough_value is None or y_data[idx] != last_trough_value):\n",
    "                        plt.annotate(f'{int(y_data[idx])}', xy=(x_data[idx], y_data[idx]),\n",
    "                                     xytext=(0, 10), textcoords='offset points', color='green', fontsize=10, ha='center')\n",
    "                        last_peak_value = y_data[idx]  # Обновляем последнее аннотированное значение пика\n",
    "                \n",
    "                elif idx in troughs:\n",
    "                    if y_data[idx] != last_trough_value and (last_peak_value is None or y_data[idx] != last_peak_value):\n",
    "                        plt.annotate(f'{int(y_data[idx])}', xy=(x_data[idx], y_data[idx]),\n",
    "                                     xytext=(0, -15), textcoords='offset points', color='red', fontsize=10, ha='center')\n",
    "                        last_trough_value = y_data[idx]  # Обновляем последнее аннотированное значение минимума\n",
    "            \n",
    "            # Увеличиваем цветовой индекс\n",
    "            color_index += 1\n",
    "        \n",
    "        # Очищаем списки для новой кампании\n",
    "        x_data, y_data = [], []  \n",
    "\n",
    "    # Добавляем данные для текущей кампании\n",
    "    x_data.append(row['date_group'])  # 'date_group' - название столбца с датами\n",
    "    y_data.append(row['cost'])\n",
    "    prev_campaign = campaign\n",
    "\n",
    "# Рисуем линию для последней кампании\n",
    "if len(x_data) > 0 and len(y_data) > 0:\n",
    "    plt.plot(x_data, y_data, label=prev_campaign, color=colors(color_index), linewidth=2)  # Установите желаемую толщину\n",
    "    \n",
    "    # Находим локальные максимумы и минимумы\n",
    "    peaks, troughs = find_peaks_and_troughs(x_data, y_data)\n",
    "    logging.info(f\"Campaign: {prev_campaign}, Peaks: {peaks}, Troughs: {troughs}\")  # Логирование информации\n",
    "\n",
    "    # Аннотируем локальные максимумы и минимумы\n",
    "    last_peak_value = None  # Храним последнее аннотированное значение пика\n",
    "    last_trough_value = None  # Храним последнее аннотированное значение минимума\n",
    "    \n",
    "    # Объединяем индексы пиков и низин\n",
    "    for idx in sorted(peaks + troughs):  \n",
    "        # Проверяем, является ли текущий индекс максимумом или минимумом\n",
    "        if idx in peaks:\n",
    "            if y_data[idx] != last_peak_value and (last_trough_value is None or y_data[idx] != last_trough_value):\n",
    "                plt.annotate(f'{int(y_data[idx])}', xy=(x_data[idx], y_data[idx]),\n",
    "                             xytext=(0, 10), textcoords='offset points', color='green', fontsize=10, ha='center')\n",
    "                last_peak_value = y_data[idx]  # Обновляем последнее аннотированное значение пика\n",
    "        \n",
    "        elif idx in troughs:\n",
    "            if y_data[idx] != last_trough_value and (last_peak_value is None or y_data[idx] != last_peak_value):\n",
    "                plt.annotate(f'{int(y_data[idx])}', xy=(x_data[idx], y_data[idx]),\n",
    "                             xytext=(0, -15), textcoords='offset points', color='red', fontsize=10, ha='center')\n",
    "                last_trough_value = y_data[idx]  # Обновляем последнее аннотированное значение минимума\n",
    "\n",
    "# Настройки графика\n",
    "plt.title('Стоимость рекламы по кампаниям (с изменением цвета)')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Стоимость')\n",
    "\n",
    "# Форматируем даты на оси X\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=1))  # Установка интервала для меток на оси X\n",
    "plt.gcf().autofmt_xdate()  # Автоматическая ориентация меток по оси X\n",
    "\n",
    "plt.grid(axis='y')\n",
    "plt.legend(title='Рекламные кампании')\n",
    "\n",
    "# Сохранение графика\n",
    "save_plot(plt, 'Стоимости реклам.png')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # 8. Визиты за весь период с цветовым выделением рекламной кампании (график со столбиками)\n",
    "# Фильтруем уникальные кампании\n",
    "filtered_campaigns = ads_summary_df[ads_summary_df['utm_campaign'] != 'none']['utm_campaign'].unique()\n",
    "overall_max = summary_df['visits'].max()\n",
    "# Создание графика\n",
    "plt.figure(figsize=(26, 13))\n",
    "\n",
    "# Обработка каждой кампании\n",
    "for campaign in filtered_campaigns:\n",
    "    campaign_data = summary_df[ads_summary_df['utm_campaign'] == campaign]\n",
    "    \n",
    "    # Сортировка данных по дате\n",
    "    campaign_data = campaign_data.sort_values('date_group')\n",
    "\n",
    "    # Генерация цвета для области под линией\n",
    "    color = plt.cm.tab10(filtered_campaigns.tolist().index(campaign) % 10)  # Цвет на основе индекса кампании\n",
    "\n",
    "    # Закрашиваем область по оси Y от 0 до максимума для текущей кампании\n",
    "    plt.fill_between(campaign_data['date_group'], 0, overall_max, alpha=0.3, color=color, label=campaign)\n",
    "\n",
    "    # Строим линейный график\n",
    "    plt.plot(campaign_data['date_group'], campaign_data['visits'], marker='o', color='black')\n",
    "\n",
    "plt.title('Визиты за весь период с выделением рекламной кампании')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Количество визитов')\n",
    "plt.xticks(rotation=45)  # Поворачиваем метки по оси x для лучшей читаемости\n",
    "plt.grid(axis='y')\n",
    "plt.grid(axis='x')\n",
    "\n",
    "# Убираем дублирующие метки в легенде\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "plt.tight_layout()  # Автоматическая подгонка для улучшения отображения\n",
    "\n",
    "# Сохранение графика\n",
    "save_plot(plt, 'Визиты за весь период с цветовым выделением рекламной кампании.png')\n",
    "\n",
    "\n",
    "\n",
    "# # 9. Регистрации за весь период с цветовым выделением рекламной кампании (график со столбиками)\n",
    "# Фильтруем уникальные кампании\n",
    "filtered_campaigns = ads_summary_df[ads_summary_df['utm_campaign'] != 'none']['utm_campaign'].unique()\n",
    "overall_max = summary_df['registrations'].max()\n",
    "# Создание графика\n",
    "plt.figure(figsize=(26, 13))\n",
    "\n",
    "# Обработка каждой кампании\n",
    "for campaign in filtered_campaigns:\n",
    "    campaign_data = summary_df[ads_summary_df['utm_campaign'] == campaign]\n",
    "    \n",
    "    # Сортировка данных по дате\n",
    "    campaign_data = campaign_data.sort_values('date_group')\n",
    "\n",
    "    # Генерация цвета для области под линией\n",
    "    color = plt.cm.tab10(filtered_campaigns.tolist().index(campaign) % 10)  # Цвет на основе индекса кампании\n",
    "\n",
    "    # Закрашиваем область по оси Y от 0 до общего максимума для текущей кампании\n",
    "    plt.fill_between(campaign_data['date_group'], 0, overall_max, alpha=0.3, color=color, label=campaign)\n",
    "\n",
    "    # Строим линейный график\n",
    "    plt.plot(campaign_data['date_group'], campaign_data['registrations'], marker='o', color='black')\n",
    "\n",
    "# Убираем дублирующие метки в легенде\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "plt.title('Регистрации за весь период с выделением рекламной кампании')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Количество регистраций')\n",
    "plt.xticks(rotation=45)  # Поворачиваем метки по оси x для лучшей читаемости\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()  # Автоматическая подгонка для улучшения отображения\n",
    "\n",
    "# Сохранение графика\n",
    "save_plot(plt, 'Регистрации за весь период с цветовым выделением рекламной кампании.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
